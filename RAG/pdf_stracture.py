# -*- coding: utf-8 -*-
"""PDF-Stracture.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ycGmybaVGuVesnZQlx0Ja-JRpKDdOboL

ðŸ”¹ Project: PDF â†’ Structured Data with Hugging Face

âœ… Goal

Upload a PDF â†’ Extract:

Title

Authors

Summary

Return structured JSON (no hallucination).
"""

# Install Requirements
!pip install pypdf2 transformers sentence-transformers accelerate

# Step 2: Extract Text from PDF
from PyPDF2 import PdfReader

def read_pdf(file_path):
    reader = PdfReader(file_path)
    text = ""
    for page in reader.pages:
        text += page.extract_text()
    return text

pdf_text = read_pdf("/content/sample1.pdf")
print(pdf_text[:500])  # preview

"""Step 3: Use Hugging Face Models

Weâ€™ll use:

Summarization â†’ facebook/bart-large-cnn

NER (Named Entity Recognition) â†’ dslim/bert-base-NER (to detect authors, names)

Title extraction â†’ take first lines of PDF or summarization
"""

from transformers import pipeline

# Summarizer for abstract/summary
summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

# NER for authors
ner = pipeline("ner", model="dslim/bert-base-NER", aggregation_strategy="simple")

# Extract summary
summary = summarizer(pdf_text[:2000], max_length=150, min_length=50, do_sample=False)[0]['summary_text']

# Extract names (potential authors)
entities = ner(pdf_text[:1000])  # first 1000 chars
authors = [ent['word'] for ent in entities if ent['entity_group'] == "PER"]

# Extract title (first 200 chars as heuristic)
title = pdf_text.split("\n")[0][:200]

print("Title:", title)
print("Authors:", authors)
print("Summary:", summary)

# Step 4: Build Structured JSON
import json

metadata = {
    "title": title,
    "authors": list(set(authors)),  # remove duplicates
    "summary": summary
}

with open("paper_metadata.json", "w") as f:
    json.dump(metadata, f, indent=2)

print("âœ… Saved structured data:", metadata)

